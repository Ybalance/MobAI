"""OpenAI LLM provider implementation."""

import base64
import logging
from typing import Any

import httpx

from mobile_use.infrastructure.llm.base import (
    BaseLLMProvider,
    LLMConfig,
    LLMMessage,
    LLMResponse,
)

# é…ç½®æ—¥å¿—
logger = logging.getLogger("mobile_use.llm")
logger.setLevel(logging.INFO)


class OpenAIProvider(BaseLLMProvider):
    """OpenAI API provider implementation.

    Supports GPT-4, GPT-4 Vision, and other OpenAI models.
    """

    def __init__(self, config: LLMConfig):
        super().__init__(config)
        self._client: Any = None

    async def initialize(self) -> None:
        """Initialize OpenAI client."""
        try:
            from openai import AsyncOpenAI

            # é…ç½®è¶…æ—¶ï¼šè¿æ¥è¶…æ—¶60ç§’ï¼Œè¯»å–è¶…æ—¶ä½¿ç”¨é…ç½®å€¼ï¼ˆå¤§æ¨¡å‹éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
            timeout = httpx.Timeout(
                connect=60.0,  # è¿æ¥è¶…æ—¶60ç§’
                read=float(self.config.timeout),  # è¯»å–è¶…æ—¶ä½¿ç”¨é…ç½®å€¼
                write=60.0,  # å†™å…¥è¶…æ—¶60ç§’
                pool=60.0  # è¿æ¥æ± è¶…æ—¶60ç§’
            )
            
            self._client = AsyncOpenAI(
                api_key=self.config.api_key,
                base_url=self.config.base_url,
                timeout=timeout,
                max_retries=self.config.retry_attempts  # ä½¿ç”¨é…ç½®çš„é‡è¯•æ¬¡æ•°
            )
            self._initialized = True
            logger.info(f"[OpenAI] åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.config.model}, è¯»å–è¶…æ—¶: {self.config.timeout}ç§’")
        except ImportError:
            raise ImportError(
                "OpenAI package not installed. "
                "Install with: pip install openai"
            )

    async def generate(
        self,
        prompt: str,
        system_prompt: str | None = None,
        **kwargs: Any
    ) -> str:
        """Generate text from prompt using OpenAI."""
        if not self._initialized:
            await self.initialize()

        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        print(f"\n{'='*80}")
        print(f"ğŸ¤– [AIå†³ç­–] æ¨¡å‹: {self.config.model}")
        print(f"ğŸ“ [AIè¾“å…¥] Prompté•¿åº¦: {len(prompt)}å­—ç¬¦")
        if len(prompt) <= 500:
            print(f"ğŸ“ [AIè¾“å…¥] å®Œæ•´å†…å®¹:\n{prompt}")
        else:
            print(f"ğŸ“ [AIè¾“å…¥] å†…å®¹é¢„è§ˆ:\n{prompt[:500]}...\n[å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­]")
        print("â³ [AIæ€è€ƒ] æ­£åœ¨åˆ†æå½“å‰æƒ…å†µå¹¶åˆ¶å®šæ‰§è¡Œç­–ç•¥...")
        
        response = await self._client.chat.completions.create(
            model=self.config.model,
            messages=messages,
            temperature=kwargs.get("temperature", self.config.temperature),
            max_tokens=kwargs.get("max_tokens", self.config.max_tokens),
            **self.config.extra_params
        )

        content = response.choices[0].message.content or ""
        print(f"ğŸ’­ [AIå†³ç­–] å“åº”é•¿åº¦: {len(content)}å­—ç¬¦")
        if len(content) <= 1000:
            print(f"ğŸ¯ [AIç†ç”±] å®Œæ•´å†³ç­–è¿‡ç¨‹:\n{content}")
        else:
            print(f"ğŸ¯ [AIç†ç”±] å†³ç­–æ‘˜è¦:\n{content[:1000]}...\n[å®Œæ•´å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­]")
        print(f"{'='*80}\n")
        
        # ä¿æŒåŸæœ‰çš„loggerè¾“å‡ºç”¨äºè°ƒè¯•
        logger.info(f"[LLMè¯·æ±‚] æ¨¡å‹: {self.config.model}, Prompté•¿åº¦: {len(prompt)}")
        logger.info(f"[LLMå“åº”] å“åº”é•¿åº¦: {len(content)}")
        
        return content

    async def chat(
        self,
        messages: list[LLMMessage],
        **kwargs: Any
    ) -> LLMResponse:
        """Send chat conversation to OpenAI."""
        if not self._initialized:
            await self.initialize()

        formatted_messages = []
        for msg in messages:
            if msg.images:
                # Vision model message with images
                content: list[dict[str, Any]] = [{"type": "text", "text": msg.content}]
                for image in msg.images:
                    b64_image = base64.b64encode(image).decode("utf-8")
                    content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{b64_image}"
                        }
                    })
                formatted_messages.append({
                    "role": msg.role,
                    "content": content
                })
            else:
                formatted_messages.append(msg.to_dict())

        logger.info(f"\n{'='*50}")
        logger.info(f"[LLM Chat] æ¨¡å‹: {self.config.model}, æ¶ˆæ¯æ•°: {len(formatted_messages)}")
        
        response = await self._client.chat.completions.create(
            model=self.config.model,
            messages=formatted_messages,
            temperature=kwargs.get("temperature", self.config.temperature),
            max_tokens=kwargs.get("max_tokens", self.config.max_tokens),
            **self.config.extra_params
        )

        choice = response.choices[0]
        usage = response.usage
        
        content = choice.message.content or ""
        logger.info(f"[LLMå“åº”] {content[:500]}..." if len(content) > 500 else f"[LLMå“åº”] {content}")
        if usage:
            logger.info(f"[Tokenç”¨é‡] prompt: {usage.prompt_tokens}, completion: {usage.completion_tokens}, total: {usage.total_tokens}")
        logger.info(f"{'='*50}\n")

        return LLMResponse(
            content=choice.message.content or "",
            model=response.model,
            provider="openai",
            usage={
                "prompt_tokens": usage.prompt_tokens if usage else 0,
                "completion_tokens": usage.completion_tokens if usage else 0,
                "total_tokens": usage.total_tokens if usage else 0
            },
            finish_reason=choice.finish_reason,
            raw_response=response
        )

    async def analyze_image(
        self,
        image: bytes,
        prompt: str,
        **kwargs: Any
    ) -> str:
        """Analyze image using vision-capable model."""
        if not self._initialized:
            await self.initialize()

        # ä½¿ç”¨å½“å‰é…ç½®çš„æ¨¡å‹ï¼Œå¤§å¤šæ•°ç°ä»£æ¨¡å‹éƒ½æ”¯æŒå›¾ç‰‡
        model = self.config.model
        image_size_kb = len(image) / 1024
        
        print(f"\n{'='*80}")
        print(f"ğŸ‘ï¸ [AIè§†è§‰] æ¨¡å‹: {model}")
        print(f"ğŸ–¼ï¸ [AIè§†è§‰] å›¾ç‰‡å¤§å°: {image_size_kb:.1f}KB")
        print(f"ğŸ“ [AIè§†è§‰] åˆ†æä»»åŠ¡: {prompt[:200]}..." if len(prompt) > 200 else f"ğŸ“ [AIè§†è§‰] åˆ†æä»»åŠ¡: {prompt}")
        print("ğŸ” [AIè§†è§‰] æ­£åœ¨åˆ†æå±å¹•æˆªå›¾ï¼Œè¯†åˆ«UIå…ƒç´ å’Œå½“å‰çŠ¶æ€...")
        
        b64_image = base64.b64encode(image).decode("utf-8")

        response = await self._client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{b64_image}",
                                "detail": kwargs.get("detail", "auto")
                            }
                        }
                    ]
                }
            ],
            temperature=kwargs.get("temperature", self.config.temperature),
            max_tokens=kwargs.get("max_tokens", self.config.max_tokens or 4096),
            **self.config.extra_params
        )

        content = response.choices[0].message.content or ""
        print(f"ğŸ¯ [AIè§†è§‰] åˆ†æå®Œæˆï¼Œå“åº”é•¿åº¦: {len(content)}å­—ç¬¦")
        if len(content) <= 800:
            print(f"ğŸ“Š [AIè§†è§‰] åˆ†æç»“æœ:\n{content}")
        else:
            print(f"ğŸ“Š [AIè§†è§‰] åˆ†ææ‘˜è¦:\n{content[:800]}...\n[å®Œæ•´å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­]")
        print(f"{'='*80}\n")
        
        return content

    async def close(self) -> None:
        """Close the client connection."""
        if self._client:
            await self._client.close()
            self._client = None
            self._initialized = False
